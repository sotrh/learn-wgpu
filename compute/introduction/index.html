<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Intro to Compute Pipelines | Learn Wgpu</title>
    <meta name="generator" content="VuePress 1.9.10">
    
    <meta name="description" content="">
    
    <link rel="preload" href="/learn-wgpu/assets/css/0.styles.31387520.css" as="style"><link rel="preload" href="/learn-wgpu/assets/js/app.bb09a5d4.js" as="script"><link rel="preload" href="/learn-wgpu/assets/js/3.f5b159d0.js" as="script"><link rel="preload" href="/learn-wgpu/assets/js/2.550d4958.js" as="script"><link rel="preload" href="/learn-wgpu/assets/js/56.cee7f4c8.js" as="script"><link rel="prefetch" href="/learn-wgpu/assets/js/1.2d9e178e.js"><link rel="prefetch" href="/learn-wgpu/assets/js/10.3c63d128.js"><link rel="prefetch" href="/learn-wgpu/assets/js/11.dd40382e.js"><link rel="prefetch" href="/learn-wgpu/assets/js/12.543da297.js"><link rel="prefetch" href="/learn-wgpu/assets/js/13.65b1e765.js"><link rel="prefetch" href="/learn-wgpu/assets/js/14.9bb5d107.js"><link rel="prefetch" href="/learn-wgpu/assets/js/15.dde7aaa1.js"><link rel="prefetch" href="/learn-wgpu/assets/js/16.6a14b094.js"><link rel="prefetch" href="/learn-wgpu/assets/js/17.23c5e795.js"><link rel="prefetch" href="/learn-wgpu/assets/js/18.62139fdb.js"><link rel="prefetch" href="/learn-wgpu/assets/js/19.3642e976.js"><link rel="prefetch" href="/learn-wgpu/assets/js/20.6469f8cf.js"><link rel="prefetch" href="/learn-wgpu/assets/js/21.5c77f4eb.js"><link rel="prefetch" href="/learn-wgpu/assets/js/22.c4e8e1dd.js"><link rel="prefetch" href="/learn-wgpu/assets/js/23.5c4ec933.js"><link rel="prefetch" href="/learn-wgpu/assets/js/24.7df81d3c.js"><link rel="prefetch" href="/learn-wgpu/assets/js/25.8b136054.js"><link rel="prefetch" href="/learn-wgpu/assets/js/26.ad011d23.js"><link rel="prefetch" href="/learn-wgpu/assets/js/27.9db734e3.js"><link rel="prefetch" href="/learn-wgpu/assets/js/28.e3372996.js"><link rel="prefetch" href="/learn-wgpu/assets/js/29.ff550603.js"><link rel="prefetch" href="/learn-wgpu/assets/js/30.1679c69d.js"><link rel="prefetch" href="/learn-wgpu/assets/js/31.4ef6283f.js"><link rel="prefetch" href="/learn-wgpu/assets/js/32.c8b0f8bc.js"><link rel="prefetch" href="/learn-wgpu/assets/js/33.d4e12223.js"><link rel="prefetch" href="/learn-wgpu/assets/js/34.d3638c4b.js"><link rel="prefetch" href="/learn-wgpu/assets/js/35.8a3d9603.js"><link rel="prefetch" href="/learn-wgpu/assets/js/36.d4d8862f.js"><link rel="prefetch" href="/learn-wgpu/assets/js/37.cc362948.js"><link rel="prefetch" href="/learn-wgpu/assets/js/38.96f92d6e.js"><link rel="prefetch" href="/learn-wgpu/assets/js/39.ce908571.js"><link rel="prefetch" href="/learn-wgpu/assets/js/4.5006202b.js"><link rel="prefetch" href="/learn-wgpu/assets/js/40.5f49c560.js"><link rel="prefetch" href="/learn-wgpu/assets/js/41.445c0834.js"><link rel="prefetch" href="/learn-wgpu/assets/js/42.6043904a.js"><link rel="prefetch" href="/learn-wgpu/assets/js/43.ba809ef6.js"><link rel="prefetch" href="/learn-wgpu/assets/js/44.18fe4828.js"><link rel="prefetch" href="/learn-wgpu/assets/js/45.548c112a.js"><link rel="prefetch" href="/learn-wgpu/assets/js/46.1dce86be.js"><link rel="prefetch" href="/learn-wgpu/assets/js/47.318b853c.js"><link rel="prefetch" href="/learn-wgpu/assets/js/48.a865dfef.js"><link rel="prefetch" href="/learn-wgpu/assets/js/49.f495fe68.js"><link rel="prefetch" href="/learn-wgpu/assets/js/5.e1abbc19.js"><link rel="prefetch" href="/learn-wgpu/assets/js/50.5a28b41e.js"><link rel="prefetch" href="/learn-wgpu/assets/js/51.aa072735.js"><link rel="prefetch" href="/learn-wgpu/assets/js/52.291b8f2c.js"><link rel="prefetch" href="/learn-wgpu/assets/js/53.a8ed70c7.js"><link rel="prefetch" href="/learn-wgpu/assets/js/54.8e855cd6.js"><link rel="prefetch" href="/learn-wgpu/assets/js/55.0a17bc63.js"><link rel="prefetch" href="/learn-wgpu/assets/js/57.5db37a6e.js"><link rel="prefetch" href="/learn-wgpu/assets/js/58.e2ae2e09.js"><link rel="prefetch" href="/learn-wgpu/assets/js/59.931c17b0.js"><link rel="prefetch" href="/learn-wgpu/assets/js/6.544b277c.js"><link rel="prefetch" href="/learn-wgpu/assets/js/60.5f7168cb.js"><link rel="prefetch" href="/learn-wgpu/assets/js/61.b35d751d.js"><link rel="prefetch" href="/learn-wgpu/assets/js/62.0fa8366e.js"><link rel="prefetch" href="/learn-wgpu/assets/js/63.69c18ddd.js"><link rel="prefetch" href="/learn-wgpu/assets/js/64.35d6f23e.js"><link rel="prefetch" href="/learn-wgpu/assets/js/65.124d9920.js"><link rel="prefetch" href="/learn-wgpu/assets/js/66.7871cadf.js"><link rel="prefetch" href="/learn-wgpu/assets/js/67.2735cc72.js"><link rel="prefetch" href="/learn-wgpu/assets/js/68.df3c6de0.js"><link rel="prefetch" href="/learn-wgpu/assets/js/69.bd44b11f.js"><link rel="prefetch" href="/learn-wgpu/assets/js/70.e61dd394.js"><link rel="prefetch" href="/learn-wgpu/assets/js/71.f8e41100.js"><link rel="prefetch" href="/learn-wgpu/assets/js/72.4b158759.js"><link rel="prefetch" href="/learn-wgpu/assets/js/73.ec34056b.js"><link rel="prefetch" href="/learn-wgpu/assets/js/9.ca671a61.js"><link rel="prefetch" href="/learn-wgpu/assets/js/vendors~docsearch.c4d76052.js">
    <link rel="stylesheet" href="/learn-wgpu/assets/css/0.styles.31387520.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="inner"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/learn-wgpu/" class="home-link router-link-active"><!----> <span class="site-name">Learn Wgpu</span></a> <div class="links"><!----> <div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div></div></div></header> <div class="sidebar-mask"></div> <div class="docs-layout"><aside class="sidebar"><!---->  <ul class="sidebar-links"><li><a href="/learn-wgpu/" aria-current="page" class="sidebar-link">Introduction</a></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Beginner</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/learn-wgpu/beginner/tutorial1-window/" class="sidebar-link">Dependencies and the window</a></li><li><a href="/learn-wgpu/beginner/tutorial2-surface/" class="sidebar-link">The Surface</a></li><li><a href="/learn-wgpu/beginner/tutorial3-pipeline/" class="sidebar-link">The Pipeline</a></li><li><a href="/learn-wgpu/beginner/tutorial4-buffer/" class="sidebar-link">Buffers and Indices</a></li><li><a href="/learn-wgpu/beginner/tutorial5-textures/" class="sidebar-link">Textures and bind groups</a></li><li><a href="/learn-wgpu/beginner/tutorial6-uniforms/" class="sidebar-link">Uniform buffers and a 3d camera</a></li><li><a href="/learn-wgpu/beginner/tutorial7-instancing/" class="sidebar-link">Instancing</a></li><li><a href="/learn-wgpu/beginner/tutorial8-depth/" class="sidebar-link">The Depth Buffer</a></li><li><a href="/learn-wgpu/beginner/tutorial9-models/" class="sidebar-link">Model Loading</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Intermediate</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/learn-wgpu/intermediate/tutorial10-lighting/" class="sidebar-link">Working with Lights</a></li><li><a href="/learn-wgpu/intermediate/tutorial11-normals/" class="sidebar-link">Normal Mapping</a></li><li><a href="/learn-wgpu/intermediate/tutorial12-camera/" class="sidebar-link">A Better Camera</a></li><li><a href="/learn-wgpu/intermediate/tutorial13-hdr/" class="sidebar-link">High Dynamic Range Rendering</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Compute Pipelines</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/learn-wgpu/compute/introduction/" aria-current="page" class="active sidebar-link">Intro to Compute Pipelines</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/learn-wgpu/compute/introduction/#why-gpu-compute-is-fast" class="sidebar-link">Why GPU compute is fast</a></li><li class="sidebar-sub-header"><a href="/learn-wgpu/compute/introduction/#when-should-i-use-compute-pipelines" class="sidebar-link">When should I use compute pipelines?</a></li><li class="sidebar-sub-header"><a href="/learn-wgpu/compute/introduction/#setting-up-the-device-and-queue" class="sidebar-link">Setting up the device and queue</a></li><li class="sidebar-sub-header"><a href="/learn-wgpu/compute/introduction/#compute-pipelines" class="sidebar-link">Compute Pipelines</a></li><li class="sidebar-sub-header"><a href="/learn-wgpu/compute/introduction/#workgroups" class="sidebar-link">Workgroups</a></li><li class="sidebar-sub-header"><a href="/learn-wgpu/compute/introduction/#the-global-invocation-id" class="sidebar-link">The global invocation id</a></li><li class="sidebar-sub-header"><a href="/learn-wgpu/compute/introduction/#buffers" class="sidebar-link">Buffers</a></li><li class="sidebar-sub-header"><a href="/learn-wgpu/compute/introduction/#bindgroup-setup" class="sidebar-link">Bindgroup setup</a></li><li class="sidebar-sub-header"><a href="/learn-wgpu/compute/introduction/#getting-data-out-of-the-gpu" class="sidebar-link">Getting data out of the GPU</a></li><li class="sidebar-sub-header"><a href="/learn-wgpu/compute/introduction/#conclusion" class="sidebar-link">Conclusion</a></li></ul></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Showcase</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>News</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="intro-to-compute-pipelines"><a href="#intro-to-compute-pipelines" class="header-anchor">#</a> Intro to Compute Pipelines</h1> <p>Compute pipelines are one of the most exciting features that WebGPU provides.
They allow you to run arbitrary compute workloads at speeds only possible with
modern GPU's massive core counts. You can run machine learning models on the
web, perform image manipulation without needing to set up the rendering pipeline
steps such as vertex processing and fragment shading, process massive numbers of
particles, animate hundreds of rigged characters, etc.</p> <p>There are a log of topics we could cover, and what you specifically want to use
compute shaders for might not be covered here, but hopefully it will be enough
to get you started. On top of that I'm trying a new format where I'll include less
of the boilerplate code and focus more on the concepts. The code will still be
linked at the bottom of the article if you get stuck with your implementation.</p> <h2 id="why-gpu-compute-is-fast"><a href="#why-gpu-compute-is-fast" class="header-anchor">#</a> Why GPU compute is fast</h2> <p>GPUs are generally considered to be faster than CPUs, but that's technically not
accurate. GPU processing speed is about the same as CPUs sometimes even slower.
According to <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/compare/" target="_blank" rel="noopener noreferrer">NVIDIA<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
most of their modern cards have clock speeds around 2.5 GHz.
<a href="https://www.qualcomm.com/products/mobile/snapdragon/laptops-and-tablets/snapdragon-x-elite" target="_blank" rel="noopener noreferrer">Qualcomm advertises<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
that the Snapdragon X Elite has clock speeds of 3.4 - 4.3 Ghz.</p> <p>So why are GPUs so popular for massive compute loads?</p> <p>The answer is core count. The Snapdragon X Elite has 12 cores. The RTX 5090 has a
whopping 21760 cores. That's 4 orders of magnitude difference. With some back of
the napkin math if an algorithm takes a second to run one operation on the CPU and
2 on the GPU, than given 12000 items the CPU will take 1000 seconds (about 16 minutes)
while the GPU will take 2 seconds (not accounting for sending data to / from the GPU and
setup time).</p> <p>Perhaps a demonstration is in order.</p> <iframe width="560" height="315" src="https://www.youtube.com/embed/vGWoV-8lteA?si=Sgl2Qq0CFoaGXMQa" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe> <p>GPUs are fast because they can do thousands of things at the same time. That being
said, not all algorithms benefit from leveraging this compute power.</p> <h2 id="when-should-i-use-compute-pipelines"><a href="#when-should-i-use-compute-pipelines" class="header-anchor">#</a> When should I use compute pipelines?</h2> <p>I can't possibly make a comprehensive list of all the things you could use a GPU for,
but here are some rules of thumb:</p> <ul><li>Tasks that can be easily parrallelized. GPUs don't like switching tasks, so if you
need the computation to use data from previous operations, compute shaders are likely
to be slower than a CPU based approach. If each operation can excute without any
knowledge of other operations, you can get a lot out of the GPU.</li> <li>You already have the data on the GPU. If your working with texture or model data
It can often be faster to process it with a compute shader rather than copying the data
to the CPU, modifying it, than shipping that back to the GPU.</li> <li>You have a massive amount of data. At some point the size of your data starts to outweigh
the setup time and complexity of using a compute pipeline. You'll still need to tailor
your approach to the data and processing you need to do.</li></ul> <p>Now with that out of the way, let's get started!</p> <h2 id="setting-up-the-device-and-queue"><a href="#setting-up-the-device-and-queue" class="header-anchor">#</a> Setting up the device and queue</h2> <p>Using compute shaders requires a lot less code than using a render pipeline. We
don't need a window, so we can get a WGPU instance, request and adapter, and request
a device and queue with this simple code:</p> <div class="language-rust extra-class"><pre class="language-rust"><code>    <span class="token keyword">let</span> instance <span class="token operator">=</span> <span class="token namespace">wgpu<span class="token punctuation">::</span></span><span class="token class-name">Instance</span><span class="token punctuation">::</span><span class="token function">new</span><span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token class-name">Default</span><span class="token punctuation">::</span><span class="token function">default</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">let</span> adapter <span class="token operator">=</span> instance<span class="token punctuation">.</span><span class="token function">request_adapter</span><span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token class-name">Default</span><span class="token punctuation">::</span><span class="token function">default</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">block_on</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">?</span><span class="token punctuation">;</span>
    <span class="token keyword">let</span> <span class="token punctuation">(</span>device<span class="token punctuation">,</span> queue<span class="token punctuation">)</span> <span class="token operator">=</span> adapter<span class="token punctuation">.</span><span class="token function">request_device</span><span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token class-name">Default</span><span class="token punctuation">::</span><span class="token function">default</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">block_on</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">?</span><span class="token punctuation">;</span>
</code></pre></div><div class="note"><p>I'm using <a href="https://docs.rs/pollster" target="_blank" rel="noopener noreferrer">pollster<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> to handle <code>async</code> code in these examples. You can use whatever
<code>async</code> implementation you like though. I'm also using <a href="https://docs.rs/anyhow" target="_blank" rel="noopener noreferrer">anyhow<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
for error handling.</p></div> <p>If you want more info about these calls and the potential arguments you can pass
to them check out <a href="/learn-wgpu/beginner/tutorial2-surface/">the rendering guide</a>.</p> <p>Now that we have a device to talk to the GPU let's start talking about how to set up a
compute pipeline.</p> <h2 id="compute-pipelines"><a href="#compute-pipelines" class="header-anchor">#</a> Compute Pipelines</h2> <p>Compute pipelines are a lot simpler to setup than render pipelines. We don't have to setup
the traditional vertex pipeline. Take a look!</p> <div class="language-rust extra-class"><pre class="language-rust"><code>    <span class="token keyword">let</span> shader <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">create_shader_module</span><span class="token punctuation">(</span><span class="token namespace">wgpu<span class="token punctuation">::</span></span><span class="token macro property">include_wgsl!</span><span class="token punctuation">(</span><span class="token string">&quot;introduction.wgsl&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token keyword">let</span> pipeline <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">create_compute_pipeline</span><span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token namespace">wgpu<span class="token punctuation">::</span></span><span class="token class-name">ComputePipelineDescriptor</span> <span class="token punctuation">{</span>
        label<span class="token punctuation">:</span> <span class="token class-name">Some</span><span class="token punctuation">(</span><span class="token string">&quot;Introduction Compute Pipeline&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        layout<span class="token punctuation">:</span> <span class="token class-name">None</span><span class="token punctuation">,</span>
        module<span class="token punctuation">:</span> <span class="token operator">&amp;</span>shader<span class="token punctuation">,</span>
        entry_point<span class="token punctuation">:</span> <span class="token class-name">None</span><span class="token punctuation">,</span>
        compilation_options<span class="token punctuation">:</span> <span class="token class-name">Default</span><span class="token punctuation">::</span><span class="token function">default</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        cache<span class="token punctuation">:</span> <span class="token class-name">Default</span><span class="token punctuation">::</span><span class="token function">default</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><p>I'm using the default values for everything here except the <code>label</code> and the shader <code>module</code>
that contains the actual shader code. I'm not specifying a bind group <code>layout</code> which means
wgpu will use the shader code to derive one. I don't supply an <code>entry_point</code> as WGPU will
select a function with a <code>@compute</code> tag if there is only one in the file.</p> <p>The shader code for this example is simple too:</p> <div class="language-wgsl extra-class"><pre class="language-wgsl"><code><span class="token comment">// A read-only storage buffer that stores and array of unsigned 32bit integers</span>
<span class="token punctuation">@</span><span class="token attributes attr-name">group</span><span class="token punctuation">(</span><span class="token int-literal number">0</span><span class="token punctuation">)</span> <span class="token punctuation">@</span><span class="token attributes attr-name">binding</span><span class="token punctuation">(</span><span class="token int-literal number">0</span><span class="token punctuation">)</span> <span class="token keyword">var</span><span class="token punctuation">&lt;</span><span class="token keyword">storage</span><span class="token punctuation">,</span> read<span class="token punctuation">&gt;</span> input<span class="token punctuation">:</span> <span class="token builtin">array</span><span class="token punctuation">&lt;</span><span class="token builtin">u32</span><span class="token punctuation">&gt;</span><span class="token punctuation">;</span>
<span class="token comment">// This storage buffer can be read from and written to</span>
<span class="token punctuation">@</span><span class="token attributes attr-name">group</span><span class="token punctuation">(</span><span class="token int-literal number">0</span><span class="token punctuation">)</span> <span class="token punctuation">@</span><span class="token attributes attr-name">binding</span><span class="token punctuation">(</span><span class="token int-literal number">1</span><span class="token punctuation">)</span> <span class="token keyword">var</span><span class="token punctuation">&lt;</span><span class="token keyword">storage</span><span class="token punctuation">,</span> read_write<span class="token punctuation">&gt;</span> output<span class="token punctuation">:</span> <span class="token builtin">array</span><span class="token punctuation">&lt;</span><span class="token builtin">u32</span><span class="token punctuation">&gt;</span><span class="token punctuation">;</span>

<span class="token comment">// Tells wgpu that this function is a valid compute pipeline entry_point</span>
<span class="token punctuation">@</span><span class="token attributes attr-name">compute</span>
<span class="token comment">// Specifies the &quot;dimension&quot; of this work group</span>
<span class="token punctuation">@</span><span class="token attributes attr-name">workgroup_size</span><span class="token punctuation">(</span><span class="token int-literal number">64</span><span class="token punctuation">)</span>
<span class="token keyword">fn</span> <span class="token functions function">main</span><span class="token punctuation">(</span>
    <span class="token comment">// global_invocation_id specifies our position in the invocation grid</span>
    <span class="token punctuation">@</span><span class="token builtin-attribute"><span class="token attribute attr-name">builtin</span><span class="token punctuation">(</span><span class="token built-in-values attr-value">global_invocation_id</span><span class="token punctuation">)</span></span> global_invocation_id<span class="token punctuation">:</span> <span class="token builtin">vec3</span><span class="token punctuation">&lt;</span><span class="token builtin">u32</span><span class="token punctuation">&gt;</span>
<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">let</span> index <span class="token operator">=</span> global_invocation_id<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    <span class="token keyword">let</span> total <span class="token operator">=</span> <span class="token function-calls function">arrayLength</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>input<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// workgroup_size may not be a multiple of the array size so</span>
    <span class="token comment">// we need to exit out a thread that would index out of bounds.</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>index <span class="token operator">&gt;=</span> total<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token keyword">return</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token comment">// a simple copy operation</span>
    output<span class="token punctuation">[</span>global_invocation_id<span class="token punctuation">.</span>x<span class="token punctuation">]</span> <span class="token operator">=</span> input<span class="token punctuation">[</span>global_invocation_id<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre></div><p>This shader is very simple. All it does is copy the contents of one buffer to another.
The one thing I feel needs some explaining is the concept of workgroups and <code>workgroup_size</code>.</p> <h2 id="workgroups"><a href="#workgroups" class="header-anchor">#</a> Workgroups</h2> <p>While GPUs prefer that each thread can blindly process it's work, real problems
require some amount of synchronization. Compute shaders accomplish this through work groups.</p> <p>A workgroup is a group of <code>X * Y * Z</code> threads that share some information about a task.
we define the size of this workgroup using the <code>workgroup_size</code> flag. We saw an
abreviated version of that above but here's the full version:</p> <div class="language-wgsl extra-class"><pre class="language-wgsl"><code><span class="token punctuation">@</span><span class="token attributes attr-name">workgroup_size</span><span class="token punctuation">(</span><span class="token int-literal number">64</span><span class="token punctuation">,</span> <span class="token int-literal number">1</span><span class="token punctuation">,</span> <span class="token int-literal number">1</span><span class="token punctuation">)</span>
</code></pre></div><p>This means that our compute shader will create workgroups with <code>64 * 1 * 1</code> threads which simplifies
to just 64 threads per workgroup. If we instead used:</p> <div class="language-wgsl extra-class"><pre class="language-wgsl"><code><span class="token punctuation">@</span><span class="token attributes attr-name">workgroup_size</span><span class="token punctuation">(</span><span class="token int-literal number">64</span><span class="token punctuation">,</span> <span class="token int-literal number">64</span><span class="token punctuation">,</span> <span class="token int-literal number">1</span><span class="token punctuation">)</span>
</code></pre></div><p>We'd get <code>64 * 64 * 1</code> threads, or 4096 threads per workgroup.</p> <p>The max supported work group size can very depending on your device, but the WebGPU spec guarantees
that the following:</p> <ul><li>A max workgroup size X of 256</li> <li>A max workgroup size Y of 256</li> <li>A max workgroup size Z of 64</li> <li>A total workgroup size of 256</li></ul> <p>This means that we might not be able to use <code>@workgroup_size(64, 64, 1)</code> but <code>@workgroup_size(16, 16, 1)</code>
should work on most devices.</p> <div class="note"><h3 id="why-xyz"><a href="#why-xyz" class="header-anchor">#</a> Why XYZ?</h3> <p>A lot of data used in GPU programming comes in 2D and even 3D arrays. Because of this <code>workgroup_size</code>
using 3 dimensions instead of 1 to make writing multidimensional code more convenient.</p> <p>For example, a blur on a 2D image would benefit from a 2D work group so each thread would
match up to a pixel in the image. A marching cubes implementation would benefit from a 3D workgroup,
so each thread handles the geometry for one voxel in the voxel grid.</p></div> <h2 id="the-global-invocation-id"><a href="#the-global-invocation-id" class="header-anchor">#</a> The global invocation id</h2> <p>Each thread in a workgroup has an id associated with it that tells what thread what workgroup
the thread belongs to. If we access this using the <code>workgroup_id</code> built in.</p> <div class="language-wgsl extra-class"><pre class="language-wgsl"><code><span class="token punctuation">@</span><span class="token attributes attr-name">compute</span>
<span class="token punctuation">@</span><span class="token attributes attr-name">workgroup_size</span><span class="token punctuation">(</span><span class="token int-literal number">64</span><span class="token punctuation">)</span>
<span class="token keyword">fn</span> <span class="token functions function">main</span><span class="token punctuation">(</span>
    <span class="token punctuation">@</span><span class="token builtin-attribute"><span class="token attribute attr-name">builtin</span><span class="token punctuation">(</span><span class="token built-in-values attr-value">workgroup_id</span><span class="token punctuation">)</span></span> workgroup_id<span class="token punctuation">:</span> <span class="token builtin">vec3</span><span class="token punctuation">&lt;</span><span class="token builtin">u32</span><span class="token punctuation">&gt;</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token comment">// ...</span>
<span class="token punctuation">}</span>
</code></pre></div><p>Knowing where we are in the workgroup is helpful too and we do that using the
<code>local_invocation_id</code> built in.</p> <div class="language-wgsl extra-class"><pre class="language-wgsl"><code><span class="token punctuation">@</span><span class="token attributes attr-name">compute</span>
<span class="token punctuation">@</span><span class="token attributes attr-name">workgroup_size</span><span class="token punctuation">(</span><span class="token int-literal number">64</span><span class="token punctuation">)</span>
<span class="token keyword">fn</span> <span class="token functions function">main</span><span class="token punctuation">(</span>
    <span class="token punctuation">@</span><span class="token builtin-attribute"><span class="token attribute attr-name">builtin</span><span class="token punctuation">(</span><span class="token built-in-values attr-value">workgroup_id</span><span class="token punctuation">)</span></span> workgroup_id<span class="token punctuation">:</span> <span class="token builtin">vec3</span><span class="token punctuation">&lt;</span><span class="token builtin">u32</span><span class="token punctuation">&gt;</span><span class="token punctuation">,</span>
    <span class="token punctuation">@</span><span class="token builtin-attribute"><span class="token attribute attr-name">builtin</span><span class="token punctuation">(</span><span class="token built-in-values attr-value">local_invocation_id</span><span class="token punctuation">)</span></span> local_invocation_id<span class="token punctuation">:</span> <span class="token builtin">vec3</span><span class="token punctuation">&lt;</span><span class="token builtin">u32</span><span class="token punctuation">&gt;</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token comment">// ...</span>
<span class="token punctuation">}</span>
</code></pre></div><p>We can then compute our global position in the workgroup invocation grid using</p> <div class="language-wgsl extra-class"><pre class="language-wgsl"><code><span class="token keyword">let</span> id <span class="token operator">=</span> workgroup_id <span class="token operator">*</span> workgroup_size <span class="token operator">+</span> local_invocation_id<span class="token punctuation">;</span>
</code></pre></div><p>We can also just us the <code>global_invocation_id</code> builtin like we did in the shader
code listed above.</p> <h3 id="where-does-workgroup-id-come-from"><a href="#where-does-workgroup-id-come-from" class="header-anchor">#</a> Where does workgroup_id come from?</h3> <p>When we dispatch our compute shader we need to specify the X, Y, and Z dimensions
of what's called the &quot;compute shader grid&quot;. Consider this code.</p> <div class="language-rust extra-class"><pre class="language-rust"><code>
    <span class="token punctuation">{</span>
        <span class="token comment">// We specified 64 threads per workgroup in the shader, so we need to compute how many</span>
        <span class="token comment">// workgroups we need to dispatch.</span>
        <span class="token keyword">let</span> num_dispatches <span class="token operator">=</span> input_data<span class="token punctuation">.</span><span class="token function">len</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token keyword">u32</span> <span class="token operator">/</span> <span class="token number">64</span> <span class="token operator">+</span> <span class="token punctuation">(</span>input_data<span class="token punctuation">.</span><span class="token function">len</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">64</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token keyword">u32</span><span class="token punctuation">;</span>

        <span class="token keyword">let</span> <span class="token keyword">mut</span> pass <span class="token operator">=</span> encoder<span class="token punctuation">.</span><span class="token function">begin_compute_pass</span><span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token class-name">Default</span><span class="token punctuation">::</span><span class="token function">default</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        pass<span class="token punctuation">.</span><span class="token function">set_pipeline</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>pipeline<span class="token punctuation">)</span><span class="token punctuation">;</span>
        pass<span class="token punctuation">.</span><span class="token function">set_bind_group</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>bind_group<span class="token punctuation">,</span> <span class="token operator">&amp;</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        pass<span class="token punctuation">.</span><span class="token function">dispatch_workgroups</span><span class="token punctuation">(</span>num_dispatches<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
</code></pre></div><p>In the <code>pass.dispatch_workgroups()</code> call we use a grid with dimensions <code>(num_dispatches, 1, 1)</code>
which means we'll launch <code>num_dispatches * 1 * 1</code> workgroups. The GPU then assigns each workgroup
an id with the x coordinate being between 0 and <code>num_dispatches - 1</code>.</p> <p>This is important to know because if you change workgroup size, the <code>global_invocation_id</code> can change
meaning you are potentially use more threads than you need or not enough.</p> <h2 id="buffers"><a href="#buffers" class="header-anchor">#</a> Buffers</h2> <p>While I've covered buffers in the <a href="/learn-wgpu/beginner/tutorial4-buffer/">rendering guide</a>,
I'll go over them briefly here too. In WebGPU a buffer is memory on the GPU that you've
set aside. This memory can be used for anything from vertex data, to neurons in a
neural network. For the most part the GPU doesn't care what data the buffer contains,
but it does care about how that data is used.</p> <p>Here's an example of setting up an input and output buffer.</p> <div class="language-rust extra-class"><pre class="language-rust"><code>    <span class="token keyword">let</span> input_buffer <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">create_buffer_init</span><span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token class-name">BufferInitDescriptor</span> <span class="token punctuation">{</span>
        label<span class="token punctuation">:</span> <span class="token class-name">Some</span><span class="token punctuation">(</span><span class="token string">&quot;input&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        contents<span class="token punctuation">:</span> <span class="token namespace">bytemuck<span class="token punctuation">::</span></span><span class="token function">cast_slice</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>input_data<span class="token punctuation">)</span><span class="token punctuation">,</span>
        usage<span class="token punctuation">:</span> <span class="token namespace">wgpu<span class="token punctuation">::</span></span><span class="token class-name">BufferUsages</span><span class="token punctuation">::</span><span class="token constant">COPY_DST</span> <span class="token operator">|</span> <span class="token namespace">wgpu<span class="token punctuation">::</span></span><span class="token class-name">BufferUsages</span><span class="token punctuation">::</span><span class="token constant">STORAGE</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token keyword">let</span> output_buffer <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">create_buffer</span><span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token namespace">wgpu<span class="token punctuation">::</span></span><span class="token class-name">BufferDescriptor</span> <span class="token punctuation">{</span>
        label<span class="token punctuation">:</span> <span class="token class-name">Some</span><span class="token punctuation">(</span><span class="token string">&quot;output&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        size<span class="token punctuation">:</span> input_buffer<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        usage<span class="token punctuation">:</span> <span class="token namespace">wgpu<span class="token punctuation">::</span></span><span class="token class-name">BufferUsages</span><span class="token punctuation">::</span><span class="token constant">COPY_SRC</span> <span class="token operator">|</span> <span class="token namespace">wgpu<span class="token punctuation">::</span></span><span class="token class-name">BufferUsages</span><span class="token punctuation">::</span><span class="token constant">STORAGE</span><span class="token punctuation">,</span>
        mapped_at_creation<span class="token punctuation">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><p>We specifically need the <code>STORAGE</code> usage our buffer is this shader. We can
use <code>UNIFORM</code> for some things, but uniform buffers are more limited in what
size they can be and they can't be modified in the shader.</p> <h2 id="bindgroup-setup"><a href="#bindgroup-setup" class="header-anchor">#</a> Bindgroup setup</h2> <p>Again I won't go into detail about how to define bind groups here, as I've
already done that in <a href="/learn-wgpu/beginner/tutorial5-textures/">the rendering guide</a>,
but I cover the theory. In WebGPU a bind group describes resources that can
be used by the shader. These can be textures, buffers, samplers, etc. A
<code>BindGroupLayout</code> defines how these resources are grouped what shaders stages
have access to them, and how the shader will interpret the resources.</p> <p>You can manually specify the <code>BindGroupLayout</code>, but WGPU can infer the layout
based on shader code. For example:</p> <div class="language-wgsl extra-class"><pre class="language-wgsl"><code><span class="token punctuation">@</span><span class="token attributes attr-name">group</span><span class="token punctuation">(</span><span class="token int-literal number">0</span><span class="token punctuation">)</span> <span class="token punctuation">@</span><span class="token attributes attr-name">binding</span><span class="token punctuation">(</span><span class="token int-literal number">0</span><span class="token punctuation">)</span> <span class="token keyword">var</span><span class="token punctuation">&lt;</span><span class="token keyword">storage</span><span class="token punctuation">,</span> read<span class="token punctuation">&gt;</span> input<span class="token punctuation">:</span> <span class="token builtin">array</span><span class="token punctuation">&lt;</span><span class="token builtin">u32</span><span class="token punctuation">&gt;</span><span class="token punctuation">;</span>
<span class="token punctuation">@</span><span class="token attributes attr-name">group</span><span class="token punctuation">(</span><span class="token int-literal number">0</span><span class="token punctuation">)</span> <span class="token punctuation">@</span><span class="token attributes attr-name">binding</span><span class="token punctuation">(</span><span class="token int-literal number">1</span><span class="token punctuation">)</span> <span class="token keyword">var</span><span class="token punctuation">&lt;</span><span class="token keyword">storage</span><span class="token punctuation">,</span> read_write<span class="token punctuation">&gt;</span> output<span class="token punctuation">:</span> <span class="token builtin">array</span><span class="token punctuation">&lt;</span><span class="token builtin">u32</span><span class="token punctuation">&gt;</span><span class="token punctuation">;</span>
</code></pre></div><p>WGPU interprets this as a layout with 2 entries, a read only storage buffer
called <code>input</code> at binding 0, and a storage buffer that can be read from and
written to called <code>output</code> at binding 1. We can easily create a bindgroup that
satisfies this with the following code:</p> <div class="language-rust extra-class"><pre class="language-rust"><code>    <span class="token keyword">let</span> bind_group <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">create_bind_group</span><span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token namespace">wgpu<span class="token punctuation">::</span></span><span class="token class-name">BindGroupDescriptor</span> <span class="token punctuation">{</span>
        label<span class="token punctuation">:</span> <span class="token class-name">None</span><span class="token punctuation">,</span>
        layout<span class="token punctuation">:</span> <span class="token operator">&amp;</span>pipeline<span class="token punctuation">.</span><span class="token function">get_bind_group_layout</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        entries<span class="token punctuation">:</span> <span class="token operator">&amp;</span><span class="token punctuation">[</span>
            <span class="token namespace">wgpu<span class="token punctuation">::</span></span><span class="token class-name">BindGroupEntry</span> <span class="token punctuation">{</span>
                binding<span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
                resource<span class="token punctuation">:</span> input_buffer<span class="token punctuation">.</span><span class="token function">as_entire_binding</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token namespace">wgpu<span class="token punctuation">::</span></span><span class="token class-name">BindGroupEntry</span> <span class="token punctuation">{</span>
                binding<span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span>
                resource<span class="token punctuation">:</span> output_buffer<span class="token punctuation">.</span><span class="token function">as_entire_binding</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><h2 id="getting-data-out-of-the-gpu"><a href="#getting-data-out-of-the-gpu" class="header-anchor">#</a> Getting data out of the GPU</h2> <p>Depending on your applications needs, the data you process in a compute shader
may stay on the the GPU as it is only used for rendering or other compute pipelines.
If you do need to get that data from the GPU to the CPU, or if you just want to
take a look at it, there is fortunately a way to do that.</p> <p>The process is a little involved so let's look at the code.</p> <div class="language-rust extra-class"><pre class="language-rust"><code><span class="token punctuation">{</span>
        <span class="token comment">// The mapping process is async, so we'll need to create a channel to get</span>
        <span class="token comment">// the success flag for our mapping</span>
        <span class="token keyword">let</span> <span class="token punctuation">(</span>tx<span class="token punctuation">,</span> rx<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token function">channel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// We send the success or failure of our mapping via a callback</span>
        temp_buffer<span class="token punctuation">.</span><span class="token function">map_async</span><span class="token punctuation">(</span><span class="token namespace">wgpu<span class="token punctuation">::</span></span><span class="token class-name">MapMode</span><span class="token punctuation">::</span><span class="token class-name">Read</span><span class="token punctuation">,</span> <span class="token punctuation">..</span><span class="token punctuation">,</span> <span class="token keyword">move</span> <span class="token closure-params"><span class="token closure-punctuation punctuation">|</span>result<span class="token closure-punctuation punctuation">|</span></span> tx<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">unwrap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// The callback we submitted to map async will only get called after the</span>
        <span class="token comment">// device is polled or the queue submitted</span>
        device<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token namespace">wgpu<span class="token punctuation">::</span></span><span class="token class-name">PollType</span><span class="token punctuation">::</span><span class="token class-name">Wait</span><span class="token punctuation">)</span><span class="token operator">?</span><span class="token punctuation">;</span>

        <span class="token comment">// We check if the mapping was successful here</span>
        rx<span class="token punctuation">.</span><span class="token function">recv</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">?</span><span class="token operator">?</span><span class="token punctuation">;</span>

        <span class="token comment">// We then get the bytes that were stored in the buffer</span>
        <span class="token keyword">let</span> output_data <span class="token operator">=</span> temp_buffer<span class="token punctuation">.</span><span class="token function">get_mapped_range</span><span class="token punctuation">(</span><span class="token punctuation">..</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// Now we have the data on the CPU we can do what ever we want to with it</span>
        <span class="token macro property">assert_eq!</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>input_data<span class="token punctuation">,</span> <span class="token namespace">bytemuck<span class="token punctuation">::</span></span><span class="token function">cast_slice</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>output_data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token comment">// We need to unmap the buffer to be able to use it again</span>
    temp_buffer<span class="token punctuation">.</span><span class="token function">unmap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><p>You may have noticed I used a variable called <code>temp_buffer</code> and not <code>output_buffer</code>
in the mapping. The reason for this is that we need the buffer being mapped to have
the <code>MAP_READ</code> usage. This usage is only compatable with the <code>COPY_DST</code> usage, meaning
it can't have the <code>STORAGE</code> nor the <code>UNIFORM</code> usage, meaning we can't use the buffer
in a compute shader. We get around this by creating a temporary buffer that we copy
the <code>output_buffer</code> to, and we then map that. Here's the setup code for the <code>temp_buffer</code>:</p> <div class="language-rust extra-class"><pre class="language-rust"><code>    <span class="token keyword">let</span> temp_buffer <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">create_buffer</span><span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token namespace">wgpu<span class="token punctuation">::</span></span><span class="token class-name">BufferDescriptor</span> <span class="token punctuation">{</span>
        label<span class="token punctuation">:</span> <span class="token class-name">Some</span><span class="token punctuation">(</span><span class="token string">&quot;temp&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        size<span class="token punctuation">:</span> input_buffer<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        usage<span class="token punctuation">:</span> <span class="token namespace">wgpu<span class="token punctuation">::</span></span><span class="token class-name">BufferUsages</span><span class="token punctuation">::</span><span class="token constant">COPY_DST</span> <span class="token operator">|</span> <span class="token namespace">wgpu<span class="token punctuation">::</span></span><span class="token class-name">BufferUsages</span><span class="token punctuation">::</span><span class="token constant">MAP_READ</span><span class="token punctuation">,</span>
        mapped_at_creation<span class="token punctuation">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><p>We need to perform this copy before we submit the queue.</p> <div class="language-rust extra-class"><pre class="language-rust"><code>    encoder<span class="token punctuation">.</span><span class="token function">copy_buffer_to_buffer</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>output_buffer<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>temp_buffer<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> output_buffer<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    queue<span class="token punctuation">.</span><span class="token function">submit</span><span class="token punctuation">(</span><span class="token punctuation">[</span>encoder<span class="token punctuation">.</span><span class="token function">finish</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><h2 id="conclusion"><a href="#conclusion" class="header-anchor">#</a> Conclusion</h2> <p>That's it. Not too difficult especially compared to setting up a render pipeline. Now that
we know how to use a compute pipeline we can actually start to do more interesting things.
This guide can't possible cover all the ways to use compute shaders, but I plan to cover
some of the core building blocks you need to build most algorithms. After that you can take
the concepts and apply them to your own projects!</p></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated: </span> <span class="time">8/22/2025, 4:41:49 AM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/learn-wgpu/intermediate/tutorial13-hdr/" class="prev">
          High Dynamic Range Rendering
        </a></span> <span class="next"><a href="/learn-wgpu/showcase/">
          Foreword
        </a>
        →
      </span></p></div> </main></div></div><div class="global-ui"><!----></div></div>
    <script src="/learn-wgpu/assets/js/app.bb09a5d4.js" defer></script><script src="/learn-wgpu/assets/js/3.f5b159d0.js" defer></script><script src="/learn-wgpu/assets/js/2.550d4958.js" defer></script><script src="/learn-wgpu/assets/js/56.cee7f4c8.js" defer></script>
  </body>
</html>
